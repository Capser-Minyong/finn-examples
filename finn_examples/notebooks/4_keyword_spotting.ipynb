{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['kws_mlp']\n"
     ]
    }
   ],
   "source": [
    "from finn_examples import models\n",
    "print(list(filter(lambda x: \"kws\" in x, dir(models))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel = models.kws_mlp()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape and datatype: (1, 490) DataType.INT8\n",
      "Expected output shape and datatype: (1, 1) DataType.UINT8\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected input shape and datatype: %s %s\" % (str(accel.ishape_normal), str(accel.idt)))\n",
    "print(\"Expected output shape and datatype: %s %s\" % (str(accel.oshape_normal), str(accel.odt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Validating network accuracy\n",
    "In this first part we will be looking at the overall accuracy of the network.\n",
    "\n",
    "The keyword spotting (KWS) network was trained on the Google Speech Commands v2 dataset, as published here: https://arxiv.org/abs/1804.03209\n",
    "\n",
    "We then used a feature extraction technique called Mel Frequency Cepstral Coefficients or MFCC for short.\n",
    "This method turns audio waveforms into 2D images with one channel. Similar to the one shown below:\n",
    "\n",
    "![MFCC features produced by python_speech_features](\"images/mfcc_py.png\")\n",
    "\n",
    "A more in-depth explenation of MFCC features can be found on wikipedia: https://en.wikipedia.org/wiki/Mel-frequency_cepstrum\n",
    "\n",
    "For this concrete case we used the python library [python_speech_featrues](https://github.com/jameslyons/python_speech_features) to produce these features.\n",
    "\n",
    "During the training of the KWS network we produce the MFCC features for the training and validation set and then quantize the inputs to the network to eight bit.\n",
    "We will load the pre-processed and quantized validation dataset in the next step.\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load preprocessed Google Speech Commands v2 validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input data shape: (10102, 490)\n",
      "Label shape: (10102,)\n"
     ]
    }
   ],
   "source": [
    "import pkg_resources as pk\n",
    "import numpy as np\n",
    "\n",
    "input_npy = pk.resource_filename(\"finn_examples\", \"data/python_speech_preprocessing_all_validation_KWS_data_inputs_len_10102.npy\")\n",
    "golden_out_npy = pk.resource_filename(\"finn_examples\", \"data/python_speech_preprocessing_all_validation_KWS_data_outputs_len_10102.npy\")\n",
    "\n",
    "input_data = np.load(input_npy)\n",
    "golden_out_data = np.load(golden_out_npy)\n",
    "num_samples = input_data.shape[0]\n",
    "\n",
    "print(\"Input data shape: \" + str(input_data.shape))\n",
    "print(\"Label shape: \" + str(golden_out_data.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run validation on the FPGA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accelerator output shape: (10102, 1)\n"
     ]
    }
   ],
   "source": [
    "accel.batch_size = num_samples\n",
    "accel_out_data = accel.execute(input_data)\n",
    "\n",
    "print(\"Accelerator output shape: \" + str(accel_out_data.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly predicted: 9070 / 10102 \n",
      "Incorrectly predicted: 1032 / 10102 \n",
      "Accuracy: 89.784201%\n"
     ]
    }
   ],
   "source": [
    "score = np.unique(accel_out_data.flatten() == golden_out_data.flatten(), return_counts=True)\n",
    "print(\"Correctly predicted: %d / %d \" % (score[1][1], num_samples))\n",
    "print(\"Incorrectly predicted: %d / %d \" % (score[1][0], num_samples))\n",
    "print(\"Accuracy: %f%%\" % (100.0 * score[1][1] / num_samples))"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here you should se an accuracy of about 88.76 %."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Assessing network throughput\n",
    "\n",
    "Now we will take a look at how fast the FPGA can process the whole validation dataset."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Using a naive timing benchmark from the notebook"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_validation():\n",
    "    accel_out_data = accel.execute(input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 loops, best of 3: 69 ms per loop\n"
     ]
    }
   ],
   "source": [
    "full_validation_time = %timeit -n 5 -o run_validation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146301.715477 images per second including data movement\n"
     ]
    }
   ],
   "source": [
    "print(f\"{(num_samples / float(full_validation_time.best)):.0f} samples per second including data movement\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the result of over 140 thousand inferences per second is already very good, this naive benchmark\n",
    "also includes data movement from and to the FPGA and it is dificult to assess how much time is spent on\n",
    "which part of running the FINN accelerator.\n",
    "\n",
    "### Using the built-in performance benchmark\n",
    "\n",
    "To measure the performance of indivudual components of the PYNQ stack and the FINN accelerator on the FPGA,\n",
    "FINN comes with a buit-in benchmark. This benchmark computes the throughput of the FINN accelerator as seen on the FPGA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DRAM_in_bandwidth[Mb/s]': 121.19740179165815,\n",
       " 'DRAM_out_bandwidth[Mb/s]': 0.24734163630950642,\n",
       " 'batch_size': 10102,\n",
       " 'copy_input_data_to_device[ms]': 26.500940322875977,\n",
       " 'copy_output_data_from_device[ms]': 0.23293495178222656,\n",
       " 'fclk[mhz]': 100.0,\n",
       " 'fold_input[ms]': 0.16808509826660156,\n",
       " 'pack_input[ms]': 0.1747608184814453,\n",
       " 'runtime[ms]': 40.842294692993164,\n",
       " 'throughput[images/s]': 247341.63630950643,\n",
       " 'unfold_output[ms]': 0.19407272338867188,\n",
       " 'unpack_output[ms]': 1.2056827545166016}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accel.throughput_test()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}