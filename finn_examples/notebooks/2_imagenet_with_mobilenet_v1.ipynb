{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize the accelerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%microblaze/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "try {\n",
       "require(['notebook/js/codecell'], function(codecell) {\n",
       "  codecell.CodeCell.options_default.highlight_modes[\n",
       "      'magic_text/x-csrc'] = {'reg':[/^%%pybind11/]};\n",
       "  Jupyter.notebook.events.one('kernel_ready.Kernel', function(){\n",
       "      Jupyter.notebook.get_cells().map(function(cell){\n",
       "          if (cell.cell_type == 'code'){ cell.auto_highlight(); } }) ;\n",
       "  });\n",
       "});\n",
       "} catch (e) {};\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['_imagenet_top5inds_io_shape_dict', 'mobilenetv1_w4a4_imagenet']\n"
     ]
    }
   ],
   "source": [
    "from finn_examples import models\n",
    "print(list(filter(lambda x: \"imagenet\" in x, dir(models))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pynq.Device.active_device.name does not correctly resolve target platform automatically (for \"ZCU102\")\n",
    "#accel = models.mobilenetv1_w4a4_imagenet()\n",
    "#accel = models.mobilenetv1_w4a4_imagenet(\"ZCU102\")\n",
    "\n",
    "from finn_examples import driver\n",
    "accel = driver.FINNExampleOverlay(\"/home/xilinx/mobilenetv1-w4a4/bitfile/finn-accel.bit\", \n",
    "                                  \"zynq-iodma\", \n",
    "                                  models._imagenet_top5inds_io_shape_dict,\n",
    "                                  batch_size=1, fclk_mhz=100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Expected input shape and datatype: (1, 224, 224, 3) DataType.UINT8\n",
      "Expected output shape and datatype: (1, 1, 1, 5) DataType.UINT16\n"
     ]
    }
   ],
   "source": [
    "print(\"Expected input shape and datatype: %s %s\" % (str(accel.ishape_normal), str(accel.idt)))\n",
    "print(\"Expected output shape and datatype: %s %s\" % (str(accel.oshape_normal), str(accel.odt)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the ImageNet validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image\n",
    "from dataset_loading import FileQueue, ImgQueue\n",
    "\n",
    "#import os\n",
    "#valdir = os.environ[\"IMAGENET_VAL_PATH\"]\n",
    "\n",
    "valdir = \"/home/xilinx/dataset/ILSVRC2012_img_val/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def img_resize(img, size):\n",
    "    w, h = img.size\n",
    "    if (w <= h and w == size) or (h <= w and h == size):\n",
    "        return img\n",
    "    if w < h:\n",
    "        ow = size\n",
    "        oh = int(size * h / w)\n",
    "        return img.resize((ow, oh), Image.BILINEAR)\n",
    "    else:\n",
    "        oh = size\n",
    "        ow = int(size * w / h)\n",
    "        return img.resize((ow, oh), Image.BILINEAR)\n",
    "\n",
    "def img_center_crop(img, size):\n",
    "    crop_height, crop_width = (size, size)\n",
    "    image_width, image_height = img.size\n",
    "\n",
    "    crop_top = int(round((image_height - crop_height) / 2.))\n",
    "    crop_left = int(round((image_width - crop_width) / 2.))\n",
    "\n",
    "    return img.crop((crop_left, crop_top, crop_left + crop_width, crop_top + crop_height))\n",
    "\n",
    "def pre_process(img_np):\n",
    "    img = Image.fromarray(img_np.astype(np.uint8))\n",
    "    img = img_resize(img, 256)\n",
    "    img = img_center_crop(img, 224)\n",
    "    img = np.array(img, dtype=np.uint8)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=1\n",
    "files = ['ILSVRC2012_val_{:08d}.JPEG'.format(i) for i in range(1,50001)]\n",
    "labels = np.loadtxt(valdir + \"val.txt\", dtype=int, usecols=1)\n",
    "file_queue = FileQueue()\n",
    "file_queue.load_epochs(list(zip(files,labels)), shuffle=False)\n",
    "img_queue = ImgQueue(maxsize=batch_size)\n",
    "img_queue.start_loaders(file_queue, num_threads=1, img_dir=valdir, transform=pre_process)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classify a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f8e2826a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "test_single_x, test_single_y = img_queue.get()\n",
    "\n",
    "# cleanup data loader\n",
    "file_queue.join()\n",
    "img_queue.join()\n",
    "\n",
    "plt.imshow(test_single_x)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_single_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input buffer shape is (1, 224, 224, 3) and datatype is uint8\n"
     ]
    }
   ],
   "source": [
    "accel_in = test_single_x.reshape(accel.ishape_normal)\n",
    "print(\"Input buffer shape is %s and datatype is %s\" % (str(accel_in.shape), str(accel_in.dtype)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accel_out = accel.execute(accel_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Top-5 classes predicted by the accelerator: \" + str(accel_out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%timeit\n",
    "accel_out = accel.execute(accel_in)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Validate accuracy on entire ImageNet validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "accel.batch_size = batch_size\n",
    "print(\"Accelerator buffer shapes are %s for input, %s for output\" % (str(accel.ishape_packed), str(accel.oshape_packed)) )\n",
    "obuf_packed = np.empty_like(accel.obuf_packed_device)\n",
    "\n",
    "files = ['ILSVRC2012_val_{:08d}.JPEG'.format(i) for i in range(1,50001)]\n",
    "labels = np.loadtxt(valdir + \"val.txt\", dtype=int, usecols=1)\n",
    "file_queue = FileQueue()\n",
    "file_queue.load_epochs(list(zip(files,labels)), shuffle=False)\n",
    "img_queue = ImgQueue(maxsize=batch_size)\n",
    "img_queue.start_loaders(file_queue, num_threads=4, img_dir=valdir, transform=pre_process)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ok = 0\n",
    "nok = 0\n",
    "i = 0\n",
    "while not img_queue.last_batch:\n",
    "\n",
    "    imgs, lbls = img_queue.get_batch(batch_size, timeout=None)\n",
    "    imgs = np.stack(imgs)\n",
    "    exp = np.array(lbls)\n",
    "    \n",
    "    ibuf_normal = imgs.reshape(accel.ishape_normal)\n",
    "    obuf_normal = accel.execute(ibuf_normal)\n",
    "    obuf_normal = obuf_normal.reshape(batch_size, -1)[:,0]\n",
    "    ret = np.bincount(obuf_normal.flatten() == exp.flatten())\n",
    "    nok += ret[0]\n",
    "    ok += ret[1]\n",
    "    i += 1\n",
    "    print(\"batch %d : total OK %d NOK %d\" % (i, ok, nok))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = 50000\n",
    "acc = 100.0 * ok / (total)\n",
    "print(\"Final top-1 accuracy: {}%\".format(acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More benchmarking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from finn_examples import models\n",
    "from finn_examples import driver\n",
    "\n",
    "accel = driver.FINNExampleOverlay(\"/home/xilinx/mobilenetv1-w4a4/bitfile/finn-accel.bit\", \n",
    "                                  \"zynq-iodma\", \n",
    "                                  models._imagenet_top5inds_io_shape_dict,\n",
    "                                  batch_size=100, fclk_mhz=100.0)\n",
    "\n",
    "accel.throughput_test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
